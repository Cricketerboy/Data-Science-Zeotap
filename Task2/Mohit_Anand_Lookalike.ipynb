{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b134d3-5393-459a-ba3a-8d69bd0498c8",
   "metadata": {},
   "source": [
    "Data Science Assignment: eCommerce Transactions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360c782e-d32c-47b2-8634-98fe89002091",
   "metadata": {},
   "source": [
    "Done by Suprith Shettigar."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f4e77ec-6a12-480a-9104-6739aef787c7",
   "metadata": {},
   "source": [
    "Task 2: Lookalike Model \n",
    "Build a Lookalike Model that takes a user's information as input and recommends 3 similar \n",
    "customers based on their profile and transaction history. The model should: \n",
    "● Use both customer and product information. \n",
    "● Assign a similarity score to each recommended customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "580e3f18-d89d-461c-a9dc-b22a6f7ef942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.impute import SimpleImputer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "714347d4-aa3d-4eef-9561-59cf3b24247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbea9e86-b980-4b5d-9572-2d0f3e8063ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LookalikeFinder:\n",
    "    def __init__(self, customers, products, transactions):\n",
    "        self.customers = customers.copy()\n",
    "        self.products = products\n",
    "        self.transactions = transactions\n",
    "        \n",
    "        # Preprocess data\n",
    "        self.preprocess_data()\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        # Convert SignupDate to days since first signup\n",
    "        self.customers['SignupDays'] = (pd.to_datetime(self.customers['SignupDate']) - \n",
    "                                        pd.to_datetime(self.customers['SignupDate']).min()).dt.days\n",
    "        \n",
    "        # Aggregate transaction data per customer\n",
    "        customer_transactions = self.transactions.groupby('CustomerID').agg({\n",
    "            'TotalValue': ['sum', 'mean', 'count'],\n",
    "            'Quantity': ['sum', 'mean']\n",
    "        }).reset_index()\n",
    "        customer_transactions.columns = ['CustomerID', 'TotalValue_Sum', 'TotalValue_Mean', \n",
    "                                          'Transaction_Count', 'Quantity_Sum', 'Quantity_Mean']\n",
    "        \n",
    "        # Merge transaction data with customer data\n",
    "        self.customer_features = self.customers.merge(customer_transactions, on='CustomerID')\n",
    "        \n",
    "        # One-hot encode Region\n",
    "        region_dummies = pd.get_dummies(self.customers['Region'], prefix='Region')\n",
    "        self.customer_features = pd.concat([self.customer_features, region_dummies], axis=1)\n",
    "        \n",
    "        # Select features\n",
    "        feature_columns = [\n",
    "            'SignupDays', 'TotalValue_Sum', 'TotalValue_Mean', \n",
    "            'Transaction_Count', 'Quantity_Sum', 'Quantity_Mean'\n",
    "        ] + list(region_dummies.columns)\n",
    "        \n",
    "        # Prepare data for scaling\n",
    "        X = self.customer_features[feature_columns]\n",
    "        \n",
    "        # Impute missing values with mean\n",
    "        imputer = SimpleImputer(strategy='mean')\n",
    "        X_imputed = imputer.fit_transform(X)\n",
    "        \n",
    "        # Scale features\n",
    "        self.scaler = StandardScaler()\n",
    "        self.X_scaled = self.scaler.fit_transform(X_imputed)\n",
    "        \n",
    "    def find_lookalikes(self, customer_id, top_n=3):\n",
    "        # Find index of target customer\n",
    "        target_customer = self.customer_features[self.customer_features['CustomerID'] == customer_id]\n",
    "        \n",
    "        if len(target_customer) == 0:\n",
    "            print(f\"Customer {customer_id} not found.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        target_idx = target_customer.index[0]\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        similarities = cosine_similarity(self.X_scaled[target_idx].reshape(1, -1), self.X_scaled)[0]\n",
    "        \n",
    "        # Exclude self and sort\n",
    "        similarities[target_idx] = -1  # Exclude self\n",
    "        top_indices = np.argsort(similarities)[::-1][:top_n]\n",
    "        \n",
    "        # Prepare lookalike results\n",
    "        lookalikes = self.customers.iloc[top_indices].copy()\n",
    "        lookalikes['SimilarityScore'] = similarities[top_indices]\n",
    "        \n",
    "        return lookalikes[['CustomerID', 'CustomerName', 'Region', 'SimilarityScore']]\n",
    "    \n",
    "    def generate_lookalike_map(self, start_id='C0001', end_id='C0020'):\n",
    "        lookalike_map = []\n",
    "        \n",
    "        # Convert CustomerID to strings if they aren't already\n",
    "        self.customers['CustomerID'] = self.customers['CustomerID'].astype(str)\n",
    "        \n",
    "        # Filter customers within the specified ID range\n",
    "        filtered_customers = self.customers[\n",
    "            (self.customers['CustomerID'] >= start_id) & \n",
    "            (self.customers['CustomerID'] <= end_id)\n",
    "        ]\n",
    "        \n",
    "        for cust_id in filtered_customers['CustomerID']:\n",
    "            lookalikes = self.find_lookalikes(cust_id)\n",
    "            for _, row in lookalikes.iterrows():\n",
    "                lookalike_map.append({\n",
    "                    'SourceCustomer': cust_id,\n",
    "                    'LookalikeCustomer': row['CustomerID'],\n",
    "                    'SimilarityScore': row['SimilarityScore']\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(lookalike_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c488c12-3d67-4123-82b6-7cbcec8936f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run\n",
    "lookalike_finder = LookalikeFinder(customers, products, transactions)\n",
    "lookalike_result = lookalike_finder.generate_lookalike_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58bc5226-3214-49cd-be67-757faf125b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookalike model completed. Results saved to Suprith_Shettigar_Lookalike.csv\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "lookalike_result.to_csv('Suprith_Shettigar_Lookalike.csv', index=False)\n",
    "print(\"Lookalike model completed. Results saved to Suprith_Shettigar_Lookalike.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c9154-82dd-43ae-9aeb-50cadf87a128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
